{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YU5poNOyCXuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e79af5-55ac-4252-d2d1-63bc9505faed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file has been created successfully.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "with open('dataset.json') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "# Flatten the data\n",
        "rows = []\n",
        "for post_id, content in data.items():\n",
        "    for annotator in content['annotators']:\n",
        "        target = annotator['target'][0] if annotator['target'] else \"No target\"  # Check if target list is empty\n",
        "        row = {\n",
        "            \"post_id\": post_id,\n",
        "            \"annotator_id\": annotator['annotator_id'],\n",
        "            \"label\": annotator['label'],\n",
        "            \"target\": target,\n",
        "            \"post_tokens\": \" \".join(content['post_tokens'])  # Join tokens into a single string\n",
        "        }\n",
        "        rows.append(row)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Write the DataFrame to a CSV file\n",
        "df.to_csv('output.csv', index=False)\n",
        "\n",
        "print(\"CSV file has been created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('output.csv')\n",
        "\n",
        "# Function to categorize tweets\n",
        "def categorize_tweet(tweet):\n",
        "    # Define your logic to categorize tweets here\n",
        "    if 'hate' in tweet.lower():  # Simplified example, you can enhance this logic\n",
        "        return 0\n",
        "    elif 'offensive' in tweet.lower():\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "# Apply the categorization function to the 'tweet' column\n",
        "df['category'] = df['tweet'].apply(categorize_tweet)\n",
        "\n",
        "# Remove duplicates from 'clean_tweets' column\n",
        "df = df.drop_duplicates(subset='clean_tweets')\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "df.to_csv('path_to_modified_file.csv', index=False)"
      ],
      "metadata": {
        "id": "xJFHTKpIE9MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('output.csv')\n",
        "\n",
        "# Function to categorize tweets\n",
        "def categorize_tweet(tweet):\n",
        "    # Define your logic to categorize tweets here\n",
        "    if 'hatespeech' in tweet.lower():  # Simplified example, you can enhance this logic\n",
        "        return 0\n",
        "    elif 'offensive' in tweet.lower():\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "# Apply the categorization function to the 'tweet' column\n",
        "df['tweet'] = df['tweet'].apply(categorize_tweet)\n",
        "\n",
        "# Remove duplicates from 'clean_tweets' column\n",
        "df = df.drop_duplicates(subset='clean_tweets')\n",
        "\n",
        "# Save the modified DataFrame to a new CSV file\n",
        "df.to_csv('modified_output.csv', index=False)"
      ],
      "metadata": {
        "id": "3pbjLXhjM7_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WYo7bmr9QNVa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}